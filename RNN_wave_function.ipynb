{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#import progressbar\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the following cell only once in the beginning###\n",
    "It will set up the computational graph of the RNN network.\n",
    "Parameters of the RNN can be adjusted at the bottom of the cell. Change to whatever value \n",
    "you deem useful, then run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " class RNNwavefunction(object):\n",
    "    def __init__(self,systemsize,cell=tf.contrib.rnn.LSTMCell,activation=tf.nn.relu,units=[10],scope='RNNwavefunction',homogeneous=True):\n",
    "        \"\"\"\n",
    "            systemsize:  int\n",
    "                         number of sites\n",
    "            cell:        a tensorflow RNN cell\n",
    "            units:       list of int\n",
    "                         number of units per RNN layer           \n",
    "            scope:       str\n",
    "                         the name of the name-space scope\n",
    "            homogeneous: bool\n",
    "                         True: use the same RNN cell at each\n",
    "                         False: use a different RNN cell at each site\n",
    "        \"\"\"\n",
    "        self.graph=tf.Graph()\n",
    "        self.scope=scope\n",
    "        self.N=systemsize\n",
    "        self.homogeneous=homogeneous\n",
    "        with self.graph.as_default():\n",
    "            with tf.variable_scope(self.scope,reuse=tf.AUTO_REUSE):\n",
    "                if homogeneous:\n",
    "                    self.lstm=[tf.nn.rnn_cell.MultiRNNCell([cell(units[n],activation=activation,name='LSTM_{0}'.format(n)) for n in range(len(units))])]\n",
    "                else:\n",
    "                    self.lstm=[tf.nn.rnn_cell.MultiRNNCell([cell(units[n],activation=activation,name='LSTM_{0}'.format(n)) for n in range(len(units))])]*self.N\n",
    "    \n",
    "    def sample(self,numsamples,inputdim):\n",
    "        \"\"\"\n",
    "            generate samples from a probability distribution parametrized by a recurrent network\n",
    "            ------------------------------------------------------------------------\n",
    "            Parameters: \n",
    "            \n",
    "            numsamples:      int\n",
    "                             number of samples to be produced\n",
    "            inputdim:        int\n",
    "                             hilbert space dimension\n",
    "    \n",
    "            ------------------------------------------------------------------------\n",
    "            Returns:         a tuple (samples,log-probs)\n",
    "             \n",
    "            samples:         tf.Tensor of shape (numsamples,systemsize)\n",
    "                             the samples in integer encoding\n",
    "            log-probs        tf.Tensor of shape (numsamples,)\n",
    "                             the log-probability of each sample \n",
    "        \"\"\"\n",
    "        with self.graph.as_default():\n",
    "            with tf.variable_scope(self.scope,reuse=tf.AUTO_REUSE):\n",
    "                b=np.zeros((numsamples,inputdim)).astype(np.float32)\n",
    "                b[:,0]=np.ones(numsamples)\n",
    "                inputs=tf.constant(dtype=tf.float32,value=b,shape=[numsamples,inputdim])\n",
    "                self.inputdim=inputs.shape[1]\n",
    "                self.outputdim=self.inputdim\n",
    "                self.numsamples=inputs.shape[0]\n",
    "                samples=[]\n",
    "                one_hot_samples=[]\n",
    "                probs=[]\n",
    "                lstm_state=self.lstm[0].zero_state(inputs.shape[0],dtype=tf.float32)\n",
    "                if not self.homogeneous:\n",
    "                    lstm_output, lstm_state = self.lstm[0](inputs, lstm_state)\n",
    "                    output=tf.layers.dense(lstm_output,self.outputdim,activation=tf.nn.softmax,name='wf_dense_{0}'.format(0))\n",
    "                    probs.append(output)\n",
    "                    temp=tf.reshape(tf.multinomial(tf.log(output),num_samples=1),[-1,])\n",
    "                    samples.append(temp)\n",
    "                    inputs2=tf.one_hot(temp,depth=self.outputdim)\n",
    "                    one_hot_samples.append(inputs2)\n",
    "\n",
    "                    for n in range(1,self.N):\n",
    "                        lstm_output, lstm_state = self.lstm[n](inputs2, lstm_state)\n",
    "                        output=tf.layers.dense(lstm_output,self.outputdim,activation=tf.nn.softmax,name='wf_dense_{0}'.format(n))\n",
    "                        probs.append(output)\n",
    "                        temp=tf.reshape(tf.multinomial(tf.log(output),num_samples=1),[-1,])\n",
    "                        samples.append(temp)\n",
    "                        inputs2=tf.one_hot(temp,depth=self.outputdim)\n",
    "                        one_hot_samples.append(inputs2)\n",
    "\n",
    "\n",
    "                else:\n",
    "                    lstm_output, lstm_state = self.lstm[0](inputs, lstm_state)\n",
    "                    output=tf.layers.dense(lstm_output,self.outputdim,activation=tf.nn.softmax,name='wf_dense_{0}'.format(0))\n",
    "                    probs.append(output)\n",
    "                    temp=tf.reshape(tf.multinomial(tf.log(output),num_samples=1),[-1,])\n",
    "                    samples.append(temp)\n",
    "                    inputs2=tf.one_hot(temp,depth=self.inputdim)\n",
    "                    one_hot_samples.append(inputs2)\n",
    "\n",
    "                    for n in range(1,self.N):\n",
    "                        lstm_output, lstm_state = self.lstm[0](inputs2, lstm_state)\n",
    "                        output=tf.layers.dense(lstm_output,self.outputdim,activation=tf.nn.softmax,name='wf_dense_{0}'.format(n))\n",
    "                        probs.append(output)\n",
    "                        temp=tf.reshape(tf.multinomial(tf.log(output),num_samples=1),[-1,])\n",
    "                        samples.append(temp)\n",
    "                        inputs2=tf.one_hot(temp,depth=self.outputdim)\n",
    "                        one_hot_samples.append(inputs2)\n",
    "\n",
    "        self.samples=tf.stack(values=samples,axis=1)\n",
    "        one_hot_samples=tf.transpose(tf.stack(values=one_hot_samples,axis=2),perm=[0,2,1])\n",
    "        temp=tf.transpose(tf.stack(values=probs,axis=2),perm=[0,2,1])\n",
    "        #mask=tf.greater(one_hot_samples,0.0001)\n",
    "        #zeros = tf.zeros_like(temp)\n",
    "        #self.log_probs=tf.reduce_sum(tf.log(tf.reduce_sum(tf.where(mask,temp,zeros),axis=2)),axis=1)\n",
    "        self.log_probs=tf.reduce_sum(tf.log(tf.reduce_sum(tf.multiply(temp,one_hot_samples),axis=2)),axis=1)\n",
    "        return self.samples,self.log_probs\n",
    "    \n",
    "    def probability(self,samples,inputdim):\n",
    "        \"\"\"\n",
    "            calculate the log-probabilities of ```samples``\n",
    "            ------------------------------------------------------------------------\n",
    "            Parameters: \n",
    "            \n",
    "            samples:         tf.Tensor\n",
    "                             a tf.placeholder of shape (number of samples,system-size) \n",
    "                             containing the input samples in integer encoding\n",
    "            inputdim:        int\n",
    "                             dimension of the input space\n",
    "                      \n",
    "            ------------------------------------------------------------------------         \n",
    "            Returns: \n",
    "            log-probs        tf.Tensor of shape (number of samples,)\n",
    "                             the log-probability of each sample         \n",
    "            \"\"\"\n",
    "        with self.graph.as_default():\n",
    "\n",
    "            self.inputdim=inputdim\n",
    "            self.outputdim=self.inputdim\n",
    "\n",
    "            self.numsamples=samples.shape[0]\n",
    "            b=np.zeros((self.numsamples,self.inputdim)).astype(np.float32)\n",
    "            b[:,0]=np.ones(self.numsamples)\n",
    "            inputs=tf.constant(dtype=tf.float32,value=b,shape=[self.numsamples,self.inputdim])\n",
    "        \n",
    "            with tf.variable_scope(self.scope,reuse=tf.AUTO_REUSE):\n",
    "                probs=[]\n",
    "\n",
    "                lstm_state=self.lstm[0].zero_state(self.numsamples,dtype=tf.float32)\n",
    "                if not self.homogeneous:\n",
    "                    lstm_output, lstm_state = self.lstm[0](inputs, lstm_state)\n",
    "                    output=tf.layers.dense(lstm_output,self.outputdim,activation=tf.nn.softmax,name='wf_dense_{0}'.format(0))\n",
    "                    probs.append(output)\n",
    "                    inputs2=tf.reshape(tf.one_hot(tf.slice(samples,begin=[np.int32(0),np.int32(0)],size=[np.int32(-1),np.int32(1)]),depth=self.outputdim),shape=[self.numsamples,self.inputdim])\n",
    "                    \n",
    "                    for n in range(1,self.N):\n",
    "                        lstm_output, lstm_state = self.lstm[n](inputs2, lstm_state)\n",
    "                        output=tf.layers.dense(lstm_output,self.outputdim,activation=tf.nn.softmax,name='wf_dense_{0}'.format(n))\n",
    "                        probs.append(output)\n",
    "                        inputs2=tf.reshape(tf.one_hot(tf.reshape(tf.slice(samples,begin=[np.int32(0),np.int32(n)],size=[np.int32(-1),np.int32(1)]),shape=[self.numsamples]),depth=self.outputdim),shape=[self.numsamples,self.inputdim])\n",
    "            \n",
    "                else:\n",
    "                    lstm_output, lstm_state = self.lstm[0](inputs, lstm_state)\n",
    "                    output=tf.layers.dense(lstm_output,self.outputdim,activation=tf.nn.softmax,name='wf_dense_{0}'.format(0))\n",
    "                    probs.append(output)\n",
    "                    inputs2=tf.reshape(tf.one_hot(tf.slice(samples,begin=[np.int32(0),np.int32(0)],size=[np.int32(-1),np.int32(1)]),depth=self.outputdim),shape=[self.numsamples,self.inputdim])\n",
    "                    \n",
    "                    for n in range(1,self.N):\n",
    "                        lstm_output, lstm_state = self.lstm[0](inputs2, lstm_state)\n",
    "                        output=tf.layers.dense(lstm_output,self.outputdim,activation=tf.nn.softmax,name='wf_dense_{0}'.format(n))\n",
    "                        probs.append(output)\n",
    "                        inputs2=tf.reshape(tf.one_hot(tf.reshape(tf.slice(samples,begin=[np.int32(0),np.int32(n)],size=[np.int32(-1),np.int32(1)]),shape=[self.numsamples]),depth=self.outputdim),shape=[self.numsamples,self.inputdim])\n",
    "            \n",
    "            temp=tf.transpose(tf.stack(values=probs,axis=2),perm=[0,2,1])\n",
    "            one_hot_samples=tf.one_hot(samples,depth=self.inputdim)\n",
    "            #mask=tf.greater(one_hot_samples,0.001)\n",
    "            #zeros = tf.zeros_like(temp)\n",
    "            #self.log_probs=tf.reduce_sum(tf.log(tf.reduce_sum(tf.where(mask,temp,zeros),axis=2)),axis=1)\n",
    "            self.log_probs=tf.reduce_sum(tf.log(tf.reduce_sum(tf.multiply(temp,one_hot_samples),axis=2)),axis=1)            \n",
    "\n",
    "            return self.log_probs\n",
    "\n",
    "\n",
    "units=[200,200]#list containing the number of hidden units for each layer of the networks\n",
    "\n",
    "N=32\n",
    "input_dim=2\n",
    "numsamples=20 #only for initialization; later I'll use a much larger value (see below)\n",
    "#cell=tf.contrib.rnn.LSTMCell()\n",
    "wf=RNNwavefunction(N,units=units,cell=tf.contrib.rnn.LSTMCell) #contains the graph with the RNNs\n",
    "sampling=wf.sample(numsamples,input_dim) #call this function once to create the dense layers\n",
    "with wf.graph.as_default(): #now initialize everything \n",
    "    inputs=tf.placeholder(dtype=tf.int32,shape=[numsamples,N])\n",
    "    learningrate=tf.placeholder(dtype=tf.float32,shape=[])\n",
    "    probs=wf.probability(inputs,input_dim)\n",
    "    optimizer=tf.train.AdamOptimizer(learning_rate=learningrate)\n",
    "    init=tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization of the RNN ###\n",
    "run the cell below only once, otherwise you will reinitialize the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with wf.graph.as_default():\n",
    "sess=tf.Session(graph=wf.graph)\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell generates samples from the LSTM, together with their log-probabilites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-22.210117 -22.186672 -22.214003 -22.208836 -22.167488 -22.155169\n",
      " -22.123138 -22.153067 -22.182789 -22.197432 -22.214367 -22.18325\n",
      " -22.21122  -22.16217  -22.209833 -22.198463 -22.162067 -22.151154\n",
      " -22.171171 -22.14102 ]\n"
     ]
    }
   ],
   "source": [
    "generated_samples,generated_log_probs=sess.run(sampling) #a tests\n",
    "print(generated_log_probs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell takes a bunch of input-samples an calculates their log-probabilities. The output of the \n",
    "cell should be identical to the output of the previous one (I'm calculating the probabilities of the generated samples again)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-22.210117 -22.186672 -22.214003 -22.208836 -22.167488 -22.155169\n",
      " -22.123138 -22.153067 -22.182789 -22.197432 -22.214367 -22.18325\n",
      " -22.21122  -22.16217  -22.209833 -22.198463 -22.162067 -22.151154\n",
      " -22.171171 -22.14102 ]\n"
     ]
    }
   ],
   "source": [
    "samples=np.random.randint(0,2,size=(numsamples,N))\n",
    "sample_log_probs=sess.run(probs,feed_dict={inputs:generated_samples})\n",
    "print(sample_log_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RNNwavefunction/multi_rnn_cell/cell_0/LSTM_0/kernel:0', 'RNNwavefunction/multi_rnn_cell/cell_0/LSTM_0/bias:0', 'RNNwavefunction/multi_rnn_cell/cell_1/LSTM_1/kernel:0', 'RNNwavefunction/multi_rnn_cell/cell_1/LSTM_1/bias:0', 'RNNwavefunction/wf_dense_0/kernel:0', 'RNNwavefunction/wf_dense_0/bias:0', 'RNNwavefunction/wf_dense_1/kernel:0', 'RNNwavefunction/wf_dense_1/bias:0', 'RNNwavefunction/wf_dense_2/kernel:0', 'RNNwavefunction/wf_dense_2/bias:0', 'RNNwavefunction/wf_dense_3/kernel:0', 'RNNwavefunction/wf_dense_3/bias:0', 'RNNwavefunction/wf_dense_4/kernel:0', 'RNNwavefunction/wf_dense_4/bias:0', 'RNNwavefunction/wf_dense_5/kernel:0', 'RNNwavefunction/wf_dense_5/bias:0', 'RNNwavefunction/wf_dense_6/kernel:0', 'RNNwavefunction/wf_dense_6/bias:0', 'RNNwavefunction/wf_dense_7/kernel:0', 'RNNwavefunction/wf_dense_7/bias:0']\n",
      "RNNwavefunction/multi_rnn_cell/cell_0/LSTM_0/kernel:0 [-3.84777226e-02 -9.84785706e-03  1.79926306e-02 -7.42774233e-02\n",
      " -6.92022741e-02 -7.47013167e-02  3.41515467e-02  5.74144721e-03\n",
      "  7.56949782e-02  8.13468546e-03 -6.10327572e-02  1.55961514e-02\n",
      " -4.06429805e-02 -2.57753581e-02  7.01290816e-02 -3.87347974e-02\n",
      " -7.26936758e-03 -4.57786955e-02 -2.26261020e-02 -4.27045487e-02\n",
      " -3.77043039e-02 -6.84628636e-02 -1.07732415e-02  1.31985247e-02\n",
      "  6.82916939e-02  2.22270265e-02  2.28481814e-02 -4.85877246e-02\n",
      " -7.53657520e-02  3.40744257e-02  1.26665756e-02 -6.03184178e-02\n",
      " -2.43196078e-02 -5.95353134e-02 -1.37004033e-02 -1.10165849e-02\n",
      "  7.20506757e-02 -7.56351128e-02  7.34204352e-02  7.42803812e-02\n",
      " -1.18631572e-02  7.63482451e-02  1.44777671e-02 -5.68249151e-02\n",
      " -5.50713018e-02  6.99322075e-02 -4.19116504e-02 -5.61949611e-03\n",
      " -7.31488019e-02 -2.00479850e-02  1.70026794e-02 -4.57862243e-02\n",
      "  4.59989309e-02  4.36963513e-02 -4.47443873e-02 -4.80051339e-02\n",
      "  7.72699863e-02  3.28876078e-04  3.66942585e-02 -5.54937944e-02\n",
      "  3.52621973e-02  3.80961150e-02 -6.83007389e-03 -5.10651097e-02\n",
      " -1.53109580e-02  4.05733511e-02  4.34942171e-02 -6.33267760e-02\n",
      "  4.55036163e-02 -6.09863587e-02  2.56654024e-02 -7.55205601e-02\n",
      " -4.04673778e-02  5.64067960e-02  2.17404440e-02  3.81811634e-02\n",
      " -6.18352890e-02  2.77641639e-02  7.66717792e-02  3.25337946e-02\n",
      " -3.37256789e-02 -6.50817528e-02 -2.45754831e-02  7.41877258e-02\n",
      " -6.55080378e-03 -1.47116110e-02  2.54636705e-02  1.77015588e-02\n",
      "  2.02862993e-02 -3.39955911e-02  1.27840042e-02 -5.74506074e-03\n",
      " -3.56797054e-02 -3.52143571e-02 -2.58893371e-02  6.24721795e-02\n",
      " -3.88991237e-02  2.94596106e-02 -6.73937798e-03 -5.25033325e-02\n",
      "  4.38007936e-02  8.04887712e-03 -3.62203121e-02  9.66987759e-03\n",
      " -2.62313150e-02  5.98235428e-02  5.99503517e-02  2.49875113e-02\n",
      "  6.67095631e-02 -5.52531928e-02 -1.80155039e-04  4.90635037e-02\n",
      "  3.02480459e-02  2.17092633e-02  3.19898501e-02 -3.58434469e-02\n",
      "  4.26968038e-02 -6.19961843e-02 -2.69510262e-02  3.42819989e-02\n",
      " -2.44782567e-02 -6.76614046e-02  3.99941355e-02 -6.93156272e-02\n",
      " -5.04060052e-02 -2.62138434e-02 -5.15910089e-02  1.50601193e-02\n",
      "  6.38786703e-02 -2.04536691e-02  3.65680084e-02  1.45503804e-02\n",
      " -9.30421054e-04  3.10499817e-02 -4.95142341e-02  1.30068362e-02\n",
      " -6.55225813e-02  7.17976093e-02 -1.40163451e-02 -4.16653529e-02\n",
      " -4.39067297e-02  7.19564706e-02 -6.66417778e-02 -6.65206909e-02\n",
      " -3.90128642e-02 -1.46014541e-02  5.09469360e-02 -2.30646804e-02\n",
      " -7.49385208e-02  3.81470919e-02 -6.10270761e-02  5.62079251e-02\n",
      " -4.81406227e-02 -5.84080070e-03 -7.51034617e-02 -6.90563247e-02\n",
      "  2.05985680e-02 -5.33901751e-02  7.15592951e-02 -2.91279070e-02\n",
      " -4.43308279e-02 -7.39986897e-02  2.61795819e-02  6.59617633e-02\n",
      "  3.01923603e-02  1.06166452e-02 -7.71415457e-02  5.58688343e-02\n",
      " -1.81912594e-02 -5.50423712e-02 -4.56023775e-02  8.83502513e-03\n",
      " -5.45418598e-02 -5.94131239e-02  6.92352206e-02  1.88163966e-02\n",
      " -1.66471377e-02  1.48256272e-02 -2.22797170e-02  2.74378136e-02\n",
      "  3.95182669e-02  6.70460910e-02  4.94838059e-02 -6.12871014e-02\n",
      " -2.96419598e-02 -6.64032102e-02  4.52716500e-02 -2.31985524e-02\n",
      " -3.29462104e-02 -7.25758374e-02 -7.29442388e-03 -4.25913446e-02\n",
      "  3.88919860e-02  3.39012817e-02  4.04294431e-02  7.22963363e-03\n",
      " -2.08571553e-04  5.76719195e-02 -5.13547100e-02  4.40866500e-02\n",
      "  5.42734563e-03  1.37342513e-03  5.26663810e-02 -3.21203023e-02\n",
      "  6.29476458e-03  5.95365167e-02  4.48292941e-02 -2.67523453e-02\n",
      "  1.00962594e-02 -5.57095930e-02  1.72240287e-02  3.12386081e-02\n",
      "  5.96504807e-02 -5.73692247e-02  9.91080701e-03  2.66413912e-02\n",
      "  3.83152366e-02 -1.14148706e-02  3.37436497e-02 -5.79692759e-02\n",
      " -1.10450014e-02  6.50151074e-03  1.74405724e-02 -5.38430363e-03\n",
      " -2.42545940e-02 -1.02528408e-02 -1.38474405e-02 -4.14554700e-02\n",
      " -6.14715777e-02  3.19133028e-02 -4.96945791e-02 -3.50214876e-02\n",
      " -2.48552151e-02 -5.34647293e-02  7.00683296e-02  5.04061729e-02\n",
      "  5.92116266e-03 -2.50764228e-02 -2.32530683e-02 -1.24868751e-02\n",
      " -3.30696553e-02 -7.98752904e-03  1.74643844e-03 -4.05864120e-02\n",
      " -1.24515444e-02 -1.31275132e-02  2.23993808e-02 -6.65860027e-02\n",
      " -5.58693483e-02 -5.23835421e-04  6.92513287e-02 -2.22846121e-03\n",
      "  2.38536894e-02  5.37836999e-02  1.36188567e-02 -3.99224758e-02\n",
      " -5.80039248e-02 -1.53321214e-02 -5.21834381e-02 -7.11282268e-02\n",
      " -5.22840060e-02  5.89638501e-02  6.13985658e-02 -5.85386157e-03\n",
      "  1.80108026e-02 -5.86040616e-02 -2.50538960e-02 -7.26125538e-02\n",
      "  4.12487984e-03  7.21556395e-02 -1.03435740e-02  5.28369099e-02\n",
      " -2.91276835e-02  5.59445322e-02  1.43059269e-02  6.91179037e-02\n",
      "  5.34750819e-02 -1.97126120e-02 -4.17256989e-02  6.22696579e-02\n",
      "  2.16902047e-03  4.18915972e-02  4.35937569e-02  4.02369276e-02\n",
      "  3.25692445e-03  1.86379775e-02  6.24743700e-02  1.42384022e-02\n",
      "  1.04188249e-02  4.94228750e-02 -4.84416075e-02  1.33800134e-02\n",
      "  7.45789111e-02 -1.79869495e-02  1.62579268e-02  6.45186007e-02\n",
      "  1.88028589e-02 -4.71849442e-02 -2.35681124e-02 -7.68787116e-02\n",
      " -7.47104883e-02 -5.05947061e-02  6.55464232e-02  5.50387055e-02\n",
      "  4.14212868e-02 -7.21927509e-02  5.08727878e-02 -5.64522929e-02\n",
      "  1.88808963e-02  4.52495664e-02 -5.88655286e-02 -6.37118667e-02\n",
      " -3.17478478e-02  6.97288662e-03  1.45258829e-02 -7.31229931e-02\n",
      "  4.93880808e-02 -7.38147125e-02  1.55124813e-02 -3.57513838e-02\n",
      "  7.37801641e-02 -5.25527596e-02 -3.76657844e-02 -7.00243637e-02\n",
      " -2.85109766e-02 -1.92532800e-02 -2.89263465e-02 -2.57883817e-02\n",
      "  7.17134327e-02 -7.31790587e-02  7.41730779e-02  1.15311220e-02\n",
      "  2.98886672e-02  3.84569913e-03  5.75847775e-02  1.68571100e-02\n",
      "  5.73738515e-02 -4.74901721e-02 -3.20688114e-02 -1.24767423e-03\n",
      " -4.38800342e-02  5.36748171e-02 -4.85504046e-02  1.53847933e-02\n",
      "  1.40606090e-02  5.12969494e-02 -5.68013564e-02  3.39282677e-02\n",
      "  4.82097715e-02  1.00949407e-03  7.58878142e-02 -5.49385585e-02\n",
      "  4.58864123e-03  6.70289397e-02  6.04634136e-02  6.73175454e-02\n",
      " -6.42980784e-02  7.99502432e-03  1.31289512e-02  8.75496864e-03\n",
      " -3.83150168e-02  2.75087729e-02 -1.62269175e-02 -6.35300279e-02\n",
      "  2.39793509e-02 -6.29571602e-02  2.22316012e-02  3.98606062e-06\n",
      "  7.35189021e-02  6.11469448e-02 -1.52915493e-02 -5.16753793e-02\n",
      "  3.67669091e-02  2.76620835e-02 -8.80790502e-03  2.64466926e-02\n",
      " -4.59315516e-02 -2.47570984e-02  5.78673780e-02  7.67443031e-02\n",
      " -1.31644458e-02 -2.11375132e-02  5.30744493e-02 -3.78026590e-02\n",
      "  2.24068686e-02  5.71319014e-02  7.43982792e-02  3.17820013e-02\n",
      " -3.09170708e-02  2.75629535e-02 -6.44835830e-02 -6.04392588e-03\n",
      " -3.31213847e-02  4.27147523e-02  7.73666203e-02  3.16915438e-02\n",
      "  4.18761522e-02 -2.01719999e-03 -1.22155249e-02  1.96727291e-02\n",
      "  1.77328289e-03  5.13121039e-02  5.33386320e-02 -2.87008770e-02\n",
      "  4.93662804e-03 -4.31266725e-02 -5.64638972e-02 -5.70590757e-02\n",
      "  2.56936625e-02  2.00900882e-02  9.92270559e-03  4.41149473e-02\n",
      " -1.05931535e-02 -7.61324912e-02 -5.02155498e-02 -2.44619474e-02\n",
      "  6.92175627e-02 -6.79991394e-02 -1.12131685e-02 -5.08686155e-03\n",
      "  1.22767016e-02  6.37303293e-02 -7.30051920e-02 -3.52030657e-02\n",
      " -5.98536022e-02 -3.29596773e-02  7.29253292e-02  5.23087978e-02\n",
      "  7.22229630e-02  2.55904347e-03 -6.09963015e-02  2.55117193e-02\n",
      " -3.86565141e-02  2.01205164e-03  5.65417558e-02 -2.08831355e-02\n",
      "  6.42667115e-02  1.86426267e-02  3.92315239e-02  2.73373723e-03\n",
      " -6.66217580e-02  6.99054450e-03 -6.04672655e-02  3.89241204e-02\n",
      "  5.31273037e-02 -6.84213340e-02  2.09076703e-02  3.54890674e-02\n",
      " -5.73588386e-02  7.03103095e-02  2.77718231e-02 -4.36478294e-02\n",
      " -4.29121591e-02 -4.67528999e-02 -2.82335170e-02  3.52614224e-02\n",
      " -3.53292041e-02  6.31920695e-02  2.61225551e-02 -6.17086142e-03\n",
      " -2.17141882e-02  7.33439922e-02 -4.62527350e-02 -5.27470671e-02\n",
      " -1.60594881e-02  7.14769214e-02 -5.97679801e-02 -2.83560194e-02\n",
      "  5.34714609e-02  5.13690114e-02 -2.52287015e-02  1.80284604e-02\n",
      " -1.18985772e-02  2.10234225e-02 -7.22307563e-02  4.74355221e-02\n",
      " -6.61760569e-04  2.27006748e-02 -5.90003356e-02  5.09219170e-02\n",
      "  5.49346954e-03 -2.95165628e-02  5.79874665e-02  3.14818248e-02\n",
      "  1.55147165e-02  4.43009734e-02  6.06743395e-02 -7.20571131e-02\n",
      "  4.39617857e-02  4.89118397e-02  2.63489708e-02  1.94851160e-02\n",
      " -2.13898271e-02 -6.46451637e-02 -6.81164116e-03  2.29895115e-04\n",
      " -2.42631361e-02  5.96374571e-02 -6.63360730e-02 -2.03904621e-02\n",
      " -7.30263367e-02  4.36729789e-02  9.41322744e-03 -3.30201909e-02\n",
      "  2.75105238e-02 -3.62749025e-02  5.74526936e-02  6.44875169e-02\n",
      "  9.45317000e-03 -7.92203844e-03 -2.24514231e-02  3.59638482e-02\n",
      " -1.63686275e-03  1.32308081e-02 -1.26880258e-02 -4.94975597e-02\n",
      "  5.77079356e-02  7.34656155e-02  1.00503117e-03 -5.95027693e-02\n",
      " -4.80447412e-02 -6.70357794e-02 -2.78111733e-02  6.87783957e-03\n",
      " -5.01757413e-02  6.52807653e-02 -2.08765678e-02 -4.33613472e-02\n",
      " -7.46109337e-02  4.21998650e-02 -7.05923066e-02 -3.62183750e-02\n",
      "  2.58211643e-02  7.29312599e-02 -2.63586715e-02  4.64991853e-02\n",
      "  3.20074335e-02  1.13778636e-02 -4.28982675e-02  4.63229567e-02\n",
      "  2.10992843e-02  2.32664794e-02 -7.90484250e-03 -1.14981011e-02\n",
      " -7.55852610e-02  2.02728137e-02  3.00765336e-02  4.80549932e-02\n",
      " -2.87078135e-02 -6.86136112e-02  3.96907330e-03  2.70204321e-02\n",
      " -3.80312093e-02 -1.47802979e-02  5.13984561e-02  3.35089862e-02\n",
      "  2.34411582e-02 -6.75534755e-02 -4.28114273e-02 -7.21894875e-02\n",
      "  3.15741077e-02 -2.34390758e-02 -5.45437410e-02  3.53471935e-03\n",
      " -4.86503989e-02 -7.97495246e-04  2.37676427e-02  6.13131672e-02\n",
      " -3.84518728e-02  6.01830035e-02 -4.55760136e-02 -3.49301472e-02\n",
      "  1.31708309e-02 -8.48338008e-03  3.88414115e-02  3.20009887e-02\n",
      "  3.11590731e-04 -3.40837613e-02 -4.17818762e-02  7.69760013e-02\n",
      "  1.04167983e-02 -5.03750890e-03  7.62276351e-02  3.62829864e-02\n",
      "  6.90252334e-02  4.61511686e-02 -7.35363662e-02  5.97837418e-02\n",
      " -6.30940497e-02  4.53374833e-02  5.60455173e-02 -2.33100355e-03\n",
      "  5.55817634e-02 -1.25369281e-02  5.66001236e-02  7.36194700e-02\n",
      "  4.08926010e-02 -1.36368051e-02  2.47496068e-02 -3.63356397e-02\n",
      "  4.93290275e-03 -6.28210008e-02 -1.75534822e-02  6.59491122e-02\n",
      " -1.35932118e-02 -6.72107190e-03 -5.77001907e-02 -7.01705739e-02\n",
      " -2.10162662e-02 -8.44348967e-03 -7.66702369e-02  9.83828306e-03\n",
      " -2.18380950e-02 -5.27982637e-02  3.24504003e-02  5.87634295e-02\n",
      " -3.93559486e-02 -1.32340416e-02 -2.53957994e-02 -4.63756099e-02\n",
      "  5.14307916e-02 -6.28761277e-02 -7.16427192e-02  5.32556921e-02\n",
      " -2.61442885e-02  6.74477220e-02  5.68255782e-05 -6.14628494e-02\n",
      " -4.14499901e-02  2.78354362e-02  5.49749881e-02 -5.34217209e-02\n",
      " -3.43820341e-02  1.30810216e-02 -4.40833457e-02 -5.36269732e-02\n",
      " -4.71652970e-02  2.14868560e-02  3.97250056e-04 -3.84911895e-02\n",
      " -2.35896222e-02 -1.19106099e-02  4.73378748e-02  1.44788027e-02\n",
      "  7.50720501e-05 -3.50083522e-02  1.59765035e-02 -6.58251122e-02\n",
      "  4.32022586e-02 -7.25989938e-02 -3.23890001e-02 -5.51955774e-02\n",
      "  3.23645771e-02  7.68182874e-02 -5.42700067e-02  4.15986925e-02\n",
      "  7.23320991e-03  7.37728179e-03 -4.95001972e-02  6.36104494e-02\n",
      " -7.11924583e-03  7.30696172e-02  1.92557871e-02  5.49009740e-02\n",
      " -6.73799217e-03 -3.45492400e-02 -3.32566202e-02 -4.41881567e-02\n",
      " -3.26312967e-02 -5.83677441e-02  1.75567120e-02  1.03485361e-02\n",
      "  5.22430986e-02 -5.03116921e-02 -4.65887934e-02  3.79180610e-02\n",
      "  2.13154927e-02  3.91551107e-03 -6.35764301e-02  4.05847505e-02\n",
      "  5.48566580e-02 -4.75443974e-02  3.64557654e-03  1.93350017e-04\n",
      "  5.79711050e-03 -6.37401119e-02  1.36552751e-03  3.25524807e-03\n",
      " -7.50057325e-02 -6.98107332e-02  4.61283475e-02 -2.97398865e-03\n",
      " -2.66021304e-02 -6.91200644e-02  1.03015080e-02  3.51394340e-02\n",
      "  3.09386849e-03 -5.17467223e-02 -5.39329723e-02 -3.00348587e-02\n",
      "  1.15207210e-02  4.62804660e-02 -6.04346842e-02  3.04976404e-02\n",
      " -6.30304217e-02  4.78883833e-02  6.38575852e-03 -4.77558598e-02\n",
      "  6.87047541e-02 -2.19166316e-02  2.52962261e-02  7.45347589e-02\n",
      " -1.54398084e-02 -3.83200534e-02  4.54485118e-02  4.67778742e-03\n",
      "  1.07385218e-02 -5.87757714e-02  6.25433773e-02 -3.74635607e-02\n",
      "  3.78613621e-02 -6.78416491e-02  6.98747933e-02 -1.06289312e-02\n",
      "  5.48626035e-02 -4.33470868e-02  3.15562338e-02 -2.03148276e-03\n",
      "  7.02958554e-03  2.15818286e-02 -2.92023681e-02  2.74413750e-02\n",
      " -3.35192457e-02  6.91387206e-02 -2.52305493e-02  1.14153549e-02\n",
      "  6.36779368e-02 -2.23867781e-02 -5.26116639e-02  5.95125407e-02\n",
      "  5.88570535e-02  1.47375539e-02  4.27407101e-02  7.29177296e-02\n",
      " -2.28247307e-02  4.39420268e-02 -3.98718677e-02 -8.77609849e-03\n",
      " -6.02896549e-02 -6.92752823e-02 -2.72440575e-02  4.64150310e-02\n",
      " -2.58186050e-02  4.30258363e-03 -5.67927957e-04  2.09789798e-02\n",
      " -6.69445470e-02 -2.83655599e-02  2.76019201e-02  2.65796036e-02\n",
      " -6.40699342e-02  5.24174869e-02  5.57542294e-02 -7.79097527e-03\n",
      "  2.64543295e-02  5.21272570e-02  1.75659135e-02 -3.98571640e-02\n",
      " -2.06444003e-02 -5.84584028e-02 -6.22123554e-02  7.35604316e-02\n",
      " -7.97171891e-03  5.81787080e-02  3.06083187e-02 -4.72917855e-02\n",
      " -5.19120097e-02 -7.65756816e-02  5.43043911e-02 -7.77846575e-03\n",
      " -2.16045603e-02  5.69794476e-02  4.21904176e-02 -5.26487678e-02\n",
      " -6.04517683e-02 -6.91949725e-02 -5.68822548e-02 -4.61745262e-02\n",
      "  4.40048426e-02  3.48362774e-02 -4.79185134e-02 -7.22254440e-02\n",
      " -2.79566832e-02 -6.79709241e-02  7.33410418e-02 -5.43832481e-02\n",
      " -1.63278729e-03 -7.70046487e-02  1.76132545e-02  9.39182192e-03]\n"
     ]
    }
   ],
   "source": [
    "with wf.graph.as_default():\n",
    "    variables_names =[v.name for v in tf.trainable_variables()]\n",
    "    print(variables_names)\n",
    "    values = sess.run(variables_names)\n",
    "    for k,v in zip(variables_names, values):\n",
    "        print(k,v[0])\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling local energy\n",
    "\n",
    "$\\langle \\Psi |H|\\Psi \\rangle=\\sum_{\\sigma,\\sigma'} \\psi_{\\sigma'} H_{\\sigma'\\sigma}\\psi_{\\sigma}\n",
    "=\\sum_{\\sigma'} |\\psi_{\\sigma'}|^2\\sum_{\\sigma} H_{\\sigma'\\sigma}\\frac{\\psi_{\\sigma}}{\\psi_{\\sigma'}}$\n",
    "\n",
    "$\\partial_{a}\\langle \\Psi |H|\\Psi \\rangle=\\sum_{\\sigma,\\sigma'} (\\partial_{a}\\psi_{\\sigma'})H_{\\sigma'\\sigma}\\psi_{\\sigma} + \\psi_{\\sigma'}H_{\\sigma'\\sigma}(\\partial_{a}\\psi_{\\sigma})=2\\sum_{\\sigma,\\sigma'} (\\partial_{a}\\psi_{\\sigma'})H_{\\sigma'\\sigma}\\psi_{\\sigma}=\n",
    "2\\sum_{\\sigma,\\sigma'}|\\psi_{\\sigma'}|^2 \\frac{(\\partial_{a}\\psi_{\\sigma'})}{\\psi_{\\sigma'}}H_{\\sigma'\\sigma}\\frac{\\psi_{\\sigma}}{\\psi_{\\sigma'}}=$\n",
    "\n",
    "$\\sum_{\\sigma'}|\\psi_{\\sigma'}|^2 \\frac{\\partial_{a}\\psi_{\\sigma'}}{\\psi_{\\sigma'}}2\\sum_{\\sigma}H_{\\sigma'\\sigma}\\frac{\\psi_{\\sigma}}{\\psi_{\\sigma'}}$\n",
    "\n",
    "The cell below implements the above stuff (not very efficiently)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XXZMatrixElemets(Jz,Jp,Bz,sigmap):\n",
    "    \"\"\"\n",
    "    computes the matrix element of the periodic XXZ Hamiltonian for a given state sigmap\n",
    "    -----------------------------------------------------------------------------------\n",
    "    Parameters:\n",
    "    Jz, Jp, Bz: np.ndarray of shape (N), (N) and (N), respectively, and dtype=float:\n",
    "                XXZ parameters\n",
    "    sigmap:     np.ndarrray of dtype=int and shape (N)\n",
    "                spin-state, integer encoded (using 0 for down spin and 1 for up spin)\n",
    "    -----------------------------------------------------------------------------------            \n",
    "    Returns: 2-tuple of type (np.ndarray,np.ndarray)\n",
    "             sigmas:         np.ndarray of dtype=int and shape (?,N)\n",
    "                             the states for which there exist non-zero matrix elements for given sigmap\n",
    "             matrixelements: np.ndarray of dtype=float and shape (?)\n",
    "                             the non-zero matrix elements\n",
    "    \"\"\"\n",
    "    sigmas=[]\n",
    "    matrixelements=[]\n",
    "    N=len(Bz)\n",
    "    #the diagonal part is simply the sum of all Sz-Sz interactions plus a B field\n",
    "    diag=np.dot(sigmap-0.5,Bz)\n",
    "    \n",
    "    for site in range(N):\n",
    "        if sigmap[site]!=sigmap[(site+1)%N]:\n",
    "            diag-=0.25*Jz[site]\n",
    "        else:\n",
    "            diag+=0.25*Jz[site]\n",
    "    matrixelements.append(diag)\n",
    "    sigmas.append(np.copy(sigmap))\n",
    "    \n",
    "    #off-diagonal part:\n",
    "    for site in range(N):\n",
    "        if sigmap[site]!=sigmap[(site+1)%N]:\n",
    "            sig=np.copy(sigmap)\n",
    "            sig[site]=sig[(site+1)%N]\n",
    "            sig[(site+1)%N]=sigmap[site]\n",
    "            sigmas.append(sig)\n",
    "            matrixelements.append(Jp[site]/2)\n",
    "    return np.array(sigmas),np.array(matrixelements)\n",
    "\n",
    "def XXZLocalEnergy(Jz,Jp,Bz,sigmap,RNN):\n",
    "    \"\"\"\n",
    "    DEPRECATED\n",
    "    computes the local energy for the XXZ model:\n",
    "    ---------------------------------------------------------------------------------\n",
    "    Parameters:\n",
    "    Jz, Jp, Bz: np.ndarray of shape (N-1), (N-1) and (N), respectively, and dtype=float:\n",
    "                XXZ parameters\n",
    "    sigmap:     np.ndarrray of dtype=int and shape (N)\n",
    "                spin-state, integer encoded (using 0 for down spin and 1 for up spin)\n",
    "    RNN:        fully initialized RNNwavefunction object\n",
    "    ----------------------------------------------------------------------------------\n",
    "    Returns:\n",
    "    the local energy (float) for sigmapp\n",
    "    \"\"\"\n",
    "    sigmas,H=XXZMatrixElemets(Jz,Jp,Bz,sigmap)#note that sigmas[0,:]==sigmap\n",
    "    with RNN.graph.as_default():\n",
    "        inputs=tf.placeholder(dtype=tf.int32,shape=[len(sigmas),len(Bz)])\n",
    "        probs=RNN.probability(inputs,inputdim=2)\n",
    "        probabilities=sess.run(probs,feed_dict={inputs:sigmas})\n",
    "    \n",
    "    return H.dot(probabilities)/probabilities[0]\n",
    "\n",
    "def XXZLocalEnergies(Jz,Jp,Bz,sigmasp,RNN):\n",
    "    \"\"\"\n",
    "    computes the local energies for the periodic XXZ model for a given spin-state sample sigmasp:\n",
    "    Eloc(\\sigma')=\\sum_{sigma} H_{\\sigma'\\sigma}\\psi_{\\sigma}/\\psi_{\\sigma'}\n",
    "    ----------------------------------------------------------------------------\n",
    "    Parameters:\n",
    "    Jz, Jp, Bz: np.ndarray of shape (N), (N) and (N), respectively, and dtype=float:\n",
    "                XXZ parameters\n",
    "    sigmasp:    np.ndarrray of dtype=int and shape (numsamples,N)\n",
    "                spin-states, integer encoded (using 0 for down spin and 1 for up spin)\n",
    "    RNN:        fully initialized RNNwavefunction object\n",
    "    ----------------------------------------------------------------------------\n",
    "    Returns:\n",
    "    np.ndarray of shape (numsamples)and dtype=float containing the local energies for each samples\n",
    "    \"\"\"\n",
    "    sigmas=np.empty((0,len(Bz)))\n",
    "    H=np.empty(0)\n",
    "    slices=[]\n",
    "    for n in range(sigmasp.shape[0]):\n",
    "        sigmap=sigmasp[n,:]\n",
    "        temp1,temp2=XXZMatrixElemets(Jz,Jp,Bz,sigmap)#note that sigmas[0,:]==sigmap\n",
    "        H=np.append(H,temp2)\n",
    "        slices.append(slice(sigmas.shape[0],sigmas.shape[0]+temp1.shape[0]))\n",
    "        sigmas=np.append(sigmas,temp1,axis=0)\n",
    "    with RNN.graph.as_default():\n",
    "        temp_inputs=tf.placeholder(dtype=tf.int32,shape=[len(sigmas),len(Bz)])\n",
    "        temp_probs=RNN.probability(temp_inputs,inputdim=2)\n",
    "        log_probabilities=sess.run(temp_probs,feed_dict={temp_inputs:sigmas})\n",
    "    localEnergies=[]\n",
    "    for n in range(len(slices)):\n",
    "        s=slices[n]\n",
    "        localEnergies.append(H[s].dot(np.exp(0.5*(log_probabilities[s]-log_probabilities[s][0]))))\n",
    "    return np.array(localEnergies)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A small check to confirm that the matrix elements are correct ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the follwing numbers should all be > 0\n",
      "[0.00746966 0.03474209 0.05454486 0.03474209 0.00746966 0.05454486\n",
      " 0.16440628 0.13713385 0.03474209 0.09005865 0.16440628 0.05454486\n",
      " 0.05454486 0.03474209 0.00746966 0.03474209 0.13713385 0.16440628\n",
      " 0.05454486 0.16440628 0.39829674 0.16440628 0.16440628 0.13713385\n",
      " 0.03474209 0.05454486 0.16440628 0.09005865 0.13713385 0.16440628\n",
      " 0.05454486 0.03474209 0.05454486 0.03474209 0.00746966 0.00746966\n",
      " 0.03474209 0.05454486 0.03474209 0.05454486 0.16440628 0.13713385\n",
      " 0.09005865 0.16440628 0.05454486 0.03474209 0.13713385 0.16440628\n",
      " 0.16440628 0.39829674 0.16440628 0.05454486 0.16440628 0.13713385\n",
      " 0.03474209 0.00746966 0.03474209 0.05454486 0.05454486 0.16440628\n",
      " 0.09005865 0.03474209 0.13713385 0.16440628 0.05454486 0.00746966\n",
      " 0.03474209 0.05454486 0.03474209 0.00746966]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import XXZED\n",
    "\n",
    "N_=8\n",
    "basis_=XXZED.binarybasisU1(N_,np.int(N_/2))\n",
    "\n",
    "basis=np.array([np.array(list(bin(b)[2::].zfill(N_))).astype(int) for b in basis_])\n",
    "\n",
    "Jz=np.ones(N_)\n",
    "Jp=-np.ones(N_)\n",
    "Bz=np.zeros(N_)\n",
    "\n",
    "H=np.zeros((basis.shape[0],basis.shape[0]))\n",
    "for n in range(basis.shape[0]):\n",
    "    sigmas,elements=XXZMatrixElemets(Jz,Jp,Bz,np.reshape(basis[n,:],(N_)))\n",
    "#     print(basis[n,:])\n",
    "#     print(sigmas)\n",
    "#     input()\n",
    "    for m in range(sigmas.shape[0]):\n",
    "        for b in range(basis.shape[0]):\n",
    "            if np.all(basis[b,:]==sigmas[m,:]):\n",
    "                H[b,n]=elements[m]\n",
    "eta,U=np.linalg.eigh(H)\n",
    "#print(np.nonzero(eta==np.min(eta))[0][0])\n",
    "print('the follwing numbers should all be > 0')\n",
    "print(U[:,np.nonzero(eta==np.min(eta))[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the following number should be ~ -3.65109341:  -3.6510934089371783\n"
     ]
    }
   ],
   "source": [
    "#print(np.sum(basis,axis=1))\n",
    "print ('the following number should be ~ -3.65109341: ',np.min(eta))\n",
    "#confirmed to be correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a checkpointed wave-function ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/maga/Dropbox/Work/RNN_wavefunctions\n",
      "INFO:tensorflow:Restoring parameters from /home/maga/Dropbox/Work/RNN_wavefunctions/RNNwavefunction_N{0}_units_200_200.ckpt\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Key RNNwavefunction/wf_dense_10/bias not found in checkpoint\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n\nCaused by op 'save/RestoreV2', defined at:\n  File \"/home/maga/software/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/maga/software/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/maga/software/anaconda3/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/maga/software/anaconda3/lib/python3.6/asyncio/base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"/home/maga/software/anaconda3/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-400d1632d323>\", line 11, in <module>\n    saver=tf.train.Saver()\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1338, in __init__\n    self.build()\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1347, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1384, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 835, in _build_internal\n    restore_sequentially, reshape)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 472, in _AddRestoreOps\n    restore_sequentially)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 886, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1463, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nNotFoundError (see above for traceback): Key RNNwavefunction/wf_dense_10/bias not found in checkpoint\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key RNNwavefunction/wf_dense_10/bias not found in checkpoint\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-400d1632d323>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mwf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0msaver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mmeanEnergy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'meanEnergy'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msavename\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mvarEnergy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'varEnergy'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msavename\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1800\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1801\u001b[0m       sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1802\u001b[0;31m                {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1804\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key RNNwavefunction/wf_dense_10/bias not found in checkpoint\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n\nCaused by op 'save/RestoreV2', defined at:\n  File \"/home/maga/software/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/maga/software/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/maga/software/anaconda3/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/maga/software/anaconda3/lib/python3.6/asyncio/base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"/home/maga/software/anaconda3/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-400d1632d323>\", line 11, in <module>\n    saver=tf.train.Saver()\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1338, in __init__\n    self.build()\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1347, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1384, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 835, in _build_internal\n    restore_sequentially, reshape)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 472, in _AddRestoreOps\n    restore_sequentially)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 886, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1463, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nNotFoundError (see above for traceback): Key RNNwavefunction/wf_dense_10/bias not found in checkpoint\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path=os.getcwd()\n",
    "print((path))\n",
    "ending='units'\n",
    "for u in units:\n",
    "    ending+='_{0}'.format(u)\n",
    "#filename='RNNwavefunction_N{0}_units'+ending+'.ckpt'\n",
    "filename='RNNwavefunction_N{0}_'+ending+'.ckpt'\n",
    "with tf.variable_scope(wf.scope,reuse=tf.AUTO_REUSE):\n",
    "    with wf.graph.as_default():\n",
    "        saver=tf.train.Saver()\n",
    "        saver.restore(sess,path+'/'+filename)\n",
    "        meanEnergy=np.load('meanEnergy'+savename+'.npy')\n",
    "        varEnergy=np.load('varEnergy'+savename+'.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanEnergy=[]\n",
    "varEnergy=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean(E): -7.96307306343168 \\pm 2.827486858884435, #samples 20000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'savename' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d8d0d4ae138e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0msaver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                 \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'meanEnergy'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msavename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmeanEnergy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'varEnergy'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msavename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvarEnergy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'savename' is not defined"
     ]
    }
   ],
   "source": [
    "path=os.getcwd()\n",
    "Jz=np.ones(N)\n",
    "Jp=-np.ones(N)\n",
    "Bz=np.zeros(N)\n",
    "\n",
    "#for a given network, generate a large number of samples:\n",
    "#numsamples_=[1000,5000,10000,20000]\n",
    "numsamples=20000\n",
    "lr=np.float32(0.00001)\n",
    "ending='units'\n",
    "for u in units:\n",
    "    ending+='_{0}'.format(u)\n",
    "filename='RNNwavefunction_N{0}_'+ending+'.ckpt'\n",
    "\n",
    "with tf.variable_scope(wf.scope,reuse=tf.AUTO_REUSE):\n",
    "    with wf.graph.as_default():\n",
    "        Eloc=tf.placeholder(dtype=tf.float32,shape=[numsamples])\n",
    "        samp=tf.placeholder(dtype=tf.int32,shape=[numsamples,N])\n",
    "        log_probs_=wf.probability(samp,inputdim=2)\n",
    "        #test=sess.run(log_probs_,feed_dict={samp:samples})\n",
    "        #print(np.linalg.norm(test-log_probs))\n",
    "        #now calculate the fake cost function:\n",
    "        cost=tf.reduce_mean(tf.multiply(log_probs_,Eloc)) #factor of 2 in the above equation \n",
    "        #print(sess.run(cost,feed_dict={Eloc:-local_energies}))\n",
    "                                          #cancels when taking log(sqrt(prob))=log(sqrt(psi^2))`\n",
    "                                          #=log(psi)=2*log(psi^2)->log(psi)=1/2*log(psi^2)=1/2*log_probs\n",
    "        gradients, variables = zip(*optimizer.compute_gradients(cost))\n",
    "        #clipped_gradients,_=tf.clip_by_global_norm(gradients,1.0)\n",
    "        optstep=optimizer.apply_gradients(zip(gradients,variables))\n",
    "        sess.run(tf.variables_initializer(optimizer.variables()),feed_dict={learningrate: lr})\n",
    "for it in range(10000):\n",
    "#     if it<10:\n",
    "#         numsamples=numsamples_[0]\n",
    "#     elif it<30:\n",
    "#         numsamples=numsamples_[1]\n",
    "#     elif it<50:\n",
    "#         numsamples=numsamples_[2]\n",
    "#     elif it<70:\n",
    "#         numsamples=numsamples_[3]        \n",
    "    samples,log_probs=sess.run(wf.sample(numsamples=numsamples,inputdim=2))\n",
    "    local_energies=XXZLocalEnergies(Jz,Jp,Bz,samples,wf)\n",
    "    meanE=np.mean(local_energies)\n",
    "    meanEnergy.append(meanE)\n",
    "    \n",
    "    varE=np.var(local_energies)\n",
    "    varEnergy.append(varE)\n",
    "    print('mean(E): {0} \\pm {1}, #samples {2}'.format(meanE,np.sqrt(varE),numsamples))\n",
    "    with tf.variable_scope(wf.scope,reuse=tf.AUTO_REUSE):\n",
    "        with wf.graph.as_default():  \n",
    "            sess.run(optstep,feed_dict={Eloc:local_energies,samp:samples,learningrate: lr})\n",
    "            if it%10==0:\n",
    "                saver=tf.train.Saver()\n",
    "                saver.save(sess,path+'/'+filename)                   \n",
    "                np.save('meanEnergy'+savename,meanEnergy)\n",
    "                np.save('varEnergy'+savename,varEnergy)\n",
    "                \n",
    "            #variables_names =[v.name for v in tf.trainable_variables()]\n",
    "            #values = sess.run(variables_names)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
