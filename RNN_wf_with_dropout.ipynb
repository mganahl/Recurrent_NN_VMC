{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import progressbar\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the following cell only once in the beginning###\n",
    "It will set up the computational graph of the RNN network.\n",
    "Parameters of the RNN can be adjusted at the bottom of the cell. Change to whatever value \n",
    "you deem useful, then run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    " class RNNwavefunction(object):\n",
    "    def __init__(self,systemsize,scope='RNNwavefunction',homogeneous=True):\n",
    "        \"\"\"\n",
    "            systemsize:  int\n",
    "                         number of sites\n",
    "            cell:        a tensorflow RNN cell\n",
    "            units:       list of int\n",
    "                         number of units per RNN layer           \n",
    "            scope:       str\n",
    "                         the name of the name-space scope\n",
    "            homogeneous: bool\n",
    "                         True: use the same RNN cell at each\n",
    "                         False: use a different RNN cell at each site\n",
    "        \"\"\"\n",
    "        self.graph=tf.Graph()\n",
    "        self.scope=scope\n",
    "        self.N=systemsize\n",
    "        self.homogeneous=homogeneous\n",
    "#         with self.graph.as_default():\n",
    "#             with tf.variable_scope(self.scope,reuse=tf.AUTO_REUSE):\n",
    "#                 if homogeneous:\n",
    "#                     self.lstm=[tf.nn.rnn_cell.MultiRNNCell([tf.contrib.rnn.DropoutWrapper(cell(units[n],activation=activation,name='LSTM_{0}'.format(n)),input_keep_prob=keepprob,output_keep_prob=0.5) for n in range(len(units))])]\n",
    "#                 else:\n",
    "#                     self.lstm=[tf.nn.rnn_cell.MultiRNNCell([tf.contrib.rnn.DropoutWrapper(cell(units[n],activation=activation,name='LSTM_{0}'.format(n)),input_keep_prob=keepprob,output_keep_prob=0.5) for n in range(len(units))])]*self.N\n",
    "\n",
    "    def sample(self,numsamples,inputdim,keepprob,cell=tf.contrib.rnn.LSTMCell,activation=tf.nn.relu,units=[10]):\n",
    "        \"\"\"\n",
    "            generate samples from a probability distribution parametrized by a recurrent network\n",
    "            ------------------------------------------------------------------------\n",
    "            Parameters: \n",
    "            \n",
    "            numsamples:      int\n",
    "                             number of samples to be produced\n",
    "            inputdim:        int\n",
    "                             hilbert space dimension\n",
    "    \n",
    "            ------------------------------------------------------------------------\n",
    "            Returns:         a tuple (samples,log-probs)\n",
    "             \n",
    "            samples:         tf.Tensor of shape (numsamples,systemsize)\n",
    "                             the samples in integer encoding\n",
    "            log-probs        tf.Tensor of shape (numsamples,)\n",
    "                             the log-probability of each sample \n",
    "        \"\"\"\n",
    "        with self.graph.as_default():\n",
    "            with tf.variable_scope(self.scope,reuse=tf.AUTO_REUSE):\n",
    "                if self.homogeneous:\n",
    "                    self.lstm=[tf.nn.rnn_cell.MultiRNNCell([tf.contrib.rnn.DropoutWrapper(cell(units[n],activation=activation,name='LSTM_{0}'.format(n)),input_keep_prob=keepprob,output_keep_prob=0.5) for n in range(len(units))])]\n",
    "                else:\n",
    "                    self.lstm=[tf.nn.rnn_cell.MultiRNNCell([tf.contrib.rnn.DropoutWrapper(cell(units[n],activation=activation,name='LSTM_{0}'.format(n)),input_keep_prob=keepprob,output_keep_prob=0.5) for n in range(len(units))])]*self.N\n",
    "\n",
    "                b=np.zeros((numsamples,inputdim)).astype(np.float32)\n",
    "                b[:,0]=np.ones(numsamples)\n",
    "                inputs=tf.constant(dtype=tf.float32,value=b,shape=[numsamples,inputdim])\n",
    "                self.inputdim=inputs.shape[1]\n",
    "                self.outputdim=self.inputdim\n",
    "                self.numsamples=inputs.shape[0]\n",
    "                samples=[]\n",
    "                one_hot_samples=[]\n",
    "                probs=[]\n",
    "                lstm_state=self.lstm[0].zero_state(inputs.shape[0],dtype=tf.float32)\n",
    "                if not self.homogeneous:\n",
    "                    lstm_output, lstm_state = self.lstm[0](inputs, lstm_state)\n",
    "                    output=tf.layers.dense(lstm_output,self.outputdim,activation=tf.nn.softmax,name='wf_dense_{0}'.format(0))\n",
    "                    probs.append(output)\n",
    "                    temp=tf.reshape(tf.multinomial(tf.log(output),num_samples=1),[-1,])\n",
    "                    samples.append(temp)\n",
    "                    inputs2=tf.one_hot(temp,depth=self.outputdim)\n",
    "                    one_hot_samples.append(inputs2)\n",
    "\n",
    "                    for n in range(1,self.N):\n",
    "                        lstm_output, lstm_state = self.lstm[n](inputs2, lstm_state)\n",
    "                        output=tf.layers.dense(lstm_output,self.outputdim,activation=tf.nn.softmax,name='wf_dense_{0}'.format(n))\n",
    "                        probs.append(output)\n",
    "                        temp=tf.reshape(tf.multinomial(tf.log(output),num_samples=1),[-1,])\n",
    "                        samples.append(temp)\n",
    "                        inputs2=tf.one_hot(temp,depth=self.outputdim)\n",
    "                        one_hot_samples.append(inputs2)\n",
    "\n",
    "\n",
    "                else:\n",
    "                    lstm_output, lstm_state = self.lstm[0](inputs, lstm_state)\n",
    "                    output=tf.layers.dense(lstm_output,self.outputdim,activation=tf.nn.softmax,name='wf_dense_{0}'.format(0))\n",
    "                    probs.append(output)\n",
    "                    temp=tf.reshape(tf.multinomial(tf.log(output),num_samples=1),[-1,])\n",
    "                    samples.append(temp)\n",
    "                    inputs2=tf.one_hot(temp,depth=self.inputdim)\n",
    "                    one_hot_samples.append(inputs2)\n",
    "\n",
    "                    for n in range(1,self.N):\n",
    "                        lstm_output, lstm_state = self.lstm[0](inputs2, lstm_state)\n",
    "                        output=tf.layers.dense(lstm_output,self.outputdim,activation=tf.nn.softmax,name='wf_dense_{0}'.format(n))\n",
    "                        probs.append(output)\n",
    "                        temp=tf.reshape(tf.multinomial(tf.log(output),num_samples=1),[-1,])\n",
    "                        samples.append(temp)\n",
    "                        inputs2=tf.one_hot(temp,depth=self.outputdim)\n",
    "                        one_hot_samples.append(inputs2)\n",
    "\n",
    "        self.samples=tf.stack(values=samples,axis=1)\n",
    "        one_hot_samples=tf.transpose(tf.stack(values=one_hot_samples,axis=2),perm=[0,2,1])\n",
    "        temp=tf.transpose(tf.stack(values=probs,axis=2),perm=[0,2,1])\n",
    "        #mask=tf.greater(one_hot_samples,0.0001)\n",
    "        #zeros = tf.zeros_like(temp)\n",
    "        #self.log_probs=tf.reduce_sum(tf.log(tf.reduce_sum(tf.where(mask,temp,zeros),axis=2)),axis=1)\n",
    "        self.log_probs=tf.reduce_sum(tf.log(tf.reduce_sum(tf.multiply(temp,one_hot_samples),axis=2)),axis=1)\n",
    "        return self.samples,self.log_probs\n",
    "    \n",
    "    def probability(self,samples,inputdim,keepprob,cell=tf.contrib.rnn.LSTMCell,activation=tf.nn.relu,units=[10]):\n",
    "        \"\"\"\n",
    "            calculate the log-probabilities of ```samples``\n",
    "            ------------------------------------------------------------------------\n",
    "            Parameters: \n",
    "            \n",
    "            samples:         tf.Tensor\n",
    "                             a tf.placeholder of shape (number of samples,system-size) \n",
    "                             containing the input samples in integer encoding\n",
    "            inputdim:        int\n",
    "                             dimension of the input space\n",
    "                      \n",
    "            ------------------------------------------------------------------------         \n",
    "            Returns: \n",
    "            log-probs        tf.Tensor of shape (number of samples,)\n",
    "                             the log-probability of each sample         \n",
    "            \"\"\"\n",
    "        with self.graph.as_default():\n",
    "\n",
    "            self.inputdim=inputdim\n",
    "            self.outputdim=self.inputdim\n",
    "\n",
    "            self.numsamples=samples.shape[0]\n",
    "            b=np.zeros((self.numsamples,self.inputdim)).astype(np.float32)\n",
    "            b[:,0]=np.ones(self.numsamples)\n",
    "            inputs=tf.constant(dtype=tf.float32,value=b,shape=[self.numsamples,self.inputdim])\n",
    "        \n",
    "            with tf.variable_scope(self.scope,reuse=tf.AUTO_REUSE):\n",
    "                if self.homogeneous:\n",
    "                    self.lstm=[tf.nn.rnn_cell.MultiRNNCell([tf.contrib.rnn.DropoutWrapper(cell(units[n],activation=activation,name='LSTM_{0}'.format(n)),input_keep_prob=keepprob,output_keep_prob=0.5) for n in range(len(units))])]\n",
    "                else:\n",
    "                    self.lstm=[tf.nn.rnn_cell.MultiRNNCell([tf.contrib.rnn.DropoutWrapper(cell(units[n],activation=activation,name='LSTM_{0}'.format(n)),input_keep_prob=keepprob,output_keep_prob=0.5) for n in range(len(units))])]*self.N\n",
    "                \n",
    "                probs=[]\n",
    "\n",
    "                lstm_state=self.lstm[0].zero_state(self.numsamples,dtype=tf.float32)\n",
    "                if not self.homogeneous:\n",
    "                    lstm_output, lstm_state = self.lstm[0](inputs, lstm_state)\n",
    "                    output=tf.layers.dense(lstm_output,self.outputdim,activation=tf.nn.softmax,name='wf_dense_{0}'.format(0))\n",
    "                    probs.append(output)\n",
    "                    inputs2=tf.reshape(tf.one_hot(tf.slice(samples,begin=[np.int32(0),np.int32(0)],size=[np.int32(-1),np.int32(1)]),depth=self.outputdim),shape=[self.numsamples,self.inputdim])\n",
    "                    \n",
    "                    for n in range(1,self.N):\n",
    "                        lstm_output, lstm_state = self.lstm[n](inputs2, lstm_state)\n",
    "                        output=tf.layers.dense(lstm_output,self.outputdim,activation=tf.nn.softmax,name='wf_dense_{0}'.format(n))\n",
    "                        probs.append(output)\n",
    "                        inputs2=tf.reshape(tf.one_hot(tf.reshape(tf.slice(samples,begin=[np.int32(0),np.int32(n)],size=[np.int32(-1),np.int32(1)]),shape=[self.numsamples]),depth=self.outputdim),shape=[self.numsamples,self.inputdim])\n",
    "            \n",
    "                else:\n",
    "                    lstm_output, lstm_state = self.lstm[0](inputs, lstm_state)\n",
    "                    output=tf.layers.dense(lstm_output,self.outputdim,activation=tf.nn.softmax,name='wf_dense_{0}'.format(0))\n",
    "                    probs.append(output)\n",
    "                    inputs2=tf.reshape(tf.one_hot(tf.slice(samples,begin=[np.int32(0),np.int32(0)],size=[np.int32(-1),np.int32(1)]),depth=self.outputdim),shape=[self.numsamples,self.inputdim])\n",
    "                    \n",
    "                    for n in range(1,self.N):\n",
    "                        lstm_output, lstm_state = self.lstm[0](inputs2, lstm_state)\n",
    "                        output=tf.layers.dense(lstm_output,self.outputdim,activation=tf.nn.softmax,name='wf_dense_{0}'.format(n))\n",
    "                        probs.append(output)\n",
    "                        inputs2=tf.reshape(tf.one_hot(tf.reshape(tf.slice(samples,begin=[np.int32(0),np.int32(n)],size=[np.int32(-1),np.int32(1)]),shape=[self.numsamples]),depth=self.outputdim),shape=[self.numsamples,self.inputdim])\n",
    "            \n",
    "            temp=tf.transpose(tf.stack(values=probs,axis=2),perm=[0,2,1])\n",
    "            one_hot_samples=tf.one_hot(samples,depth=self.inputdim)\n",
    "            #mask=tf.greater(one_hot_samples,0.001)\n",
    "            #zeros = tf.zeros_like(temp)\n",
    "            #self.log_probs=tf.reduce_sum(tf.log(tf.reduce_sum(tf.where(mask,temp,zeros),axis=2)),axis=1)\n",
    "            self.log_probs=tf.reduce_sum(tf.log(tf.reduce_sum(tf.multiply(temp,one_hot_samples),axis=2)),axis=1)\n",
    "            return self.log_probs\n",
    "\n",
    "\n",
    "units=[300]#list containing the number of hidden units for each layer of the networks\n",
    "N=8\n",
    "input_dim=2\n",
    "numsamples=20 #only for initialization; later I'll use a much larger value (see below)\n",
    "#cell=tf.contrib.rnn.LSTMCell()\n",
    "#wf=RNNwavefunction(N,units=units,cell=tf.contrib.rnn.GRUCell,activation=tf.keras.activations.linear) #contains the graph with the RNNs\n",
    "wf=RNNwavefunction(N)\n",
    "\n",
    "with wf.graph.as_default():#inserting a few placeholders into the graph\n",
    "    inputs=tf.placeholder(dtype=tf.int32,shape=[numsamples,N])\n",
    "    learningrate=tf.placeholder(dtype=tf.float32,shape=[])\n",
    "    keepprob=tf.placeholder(dtype=tf.float32,shape=[])\n",
    "sampling=wf.sample(numsamples,input_dim,keepprob,cell=tf.contrib.rnn.LSTMCell,activation=tf.keras.activations.linear) #call this function once to create the dense layers\n",
    "with wf.graph.as_default(): #now initialize everything \n",
    "    probs=wf.probability(inputs,input_dim,keepprob)\n",
    "    optimizer=tf.train.AdamOptimizer(learning_rate=learningrate)\n",
    "    init=tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization of the RNN ###\n",
    "run the cell below only once, otherwise you will reinitialize the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with wf.graph.as_default():\n",
    "sess=tf.Session(graph=wf.graph)\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell generates samples from the LSTM, together with their log-probabilites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.7172027 -5.3007636 -5.730796  -5.638402  -4.881246  -5.7099276\n",
      " -5.3763647 -5.3637514 -5.462563  -5.044448  -6.2424517 -6.037634\n",
      " -6.069004  -5.5766478 -5.574834  -5.32192   -5.193973  -4.981885\n",
      " -5.518626  -5.35106  ]\n"
     ]
    }
   ],
   "source": [
    "generated_samples,generated_log_probs=sess.run(sampling,feed_dict={keepprob: 1.0}) #a tests\n",
    "print(generated_log_probs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell takes a bunch of input-samples an calculates their log-probabilities. The output of the \n",
    "cell should be identical to the output of the previous one (I'm calculating the probabilities of the generated samples again)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.6692047 -5.5594597 -5.696536  -5.909798  -5.288148  -4.822653\n",
      " -5.083637  -5.063472  -5.712101  -6.054822  -5.721218  -5.5354805\n",
      " -5.810268  -5.8715296 -5.998554  -5.3953433 -5.3916216 -5.7642927\n",
      " -5.212789  -5.925873 ]\n"
     ]
    }
   ],
   "source": [
    "samples=np.random.randint(0,2,size=(numsamples,N))\n",
    "sample_log_probs=sess.run(probs,feed_dict={inputs:generated_samples,keepprob:1.0})\n",
    "print(sample_log_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RNNwavefunction/multi_rnn_cell/cell_0/LSTM_0/kernel:0', 'RNNwavefunction/multi_rnn_cell/cell_0/LSTM_0/bias:0', 'RNNwavefunction/wf_dense_0/kernel:0', 'RNNwavefunction/wf_dense_0/bias:0', 'RNNwavefunction/wf_dense_1/kernel:0', 'RNNwavefunction/wf_dense_1/bias:0', 'RNNwavefunction/wf_dense_2/kernel:0', 'RNNwavefunction/wf_dense_2/bias:0', 'RNNwavefunction/wf_dense_3/kernel:0', 'RNNwavefunction/wf_dense_3/bias:0', 'RNNwavefunction/wf_dense_4/kernel:0', 'RNNwavefunction/wf_dense_4/bias:0', 'RNNwavefunction/wf_dense_5/kernel:0', 'RNNwavefunction/wf_dense_5/bias:0', 'RNNwavefunction/wf_dense_6/kernel:0', 'RNNwavefunction/wf_dense_6/bias:0', 'RNNwavefunction/wf_dense_7/kernel:0', 'RNNwavefunction/wf_dense_7/bias:0']\n",
      "RNNwavefunction/multi_rnn_cell/cell_0/LSTM_0/kernel:0 [ 0.07476813  0.30780047  0.03343037 -0.0266746   0.29104358 -0.24790308\n",
      "  0.07487437 -0.09495552  0.04957685 -0.2898727   0.08468324  0.17791748\n",
      " -0.17019305  0.28364658 -0.17864157 -0.29150352 -0.23419428 -0.04210275\n",
      " -0.10498233 -0.24122564  0.2386362  -0.02201697 -0.05498606  0.31988496\n",
      " -0.03004649 -0.19065136 -0.00843656  0.02664366 -0.0763109  -0.12644497\n",
      " -0.25153     0.28195775 -0.31272674  0.21016335 -0.33382884  0.30185127\n",
      "  0.14839998 -0.02286321 -0.21923782 -0.17179285]\n"
     ]
    }
   ],
   "source": [
    "with wf.graph.as_default():\n",
    "    variables_names =[v.name for v in tf.trainable_variables()]\n",
    "    print(variables_names)\n",
    "    values = sess.run(variables_names)\n",
    "    for k,v in zip(variables_names, values):\n",
    "        print(k,v[0])\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling local energy\n",
    "\n",
    "$\\langle \\Psi |H|\\Psi \\rangle=\\sum_{\\sigma,\\sigma'} \\psi_{\\sigma'} H_{\\sigma'\\sigma}\\psi_{\\sigma}\n",
    "=\\sum_{\\sigma'} |\\psi_{\\sigma'}|^2\\sum_{\\sigma} H_{\\sigma'\\sigma}\\frac{\\psi_{\\sigma}}{\\psi_{\\sigma'}}$\n",
    "\n",
    "$\\partial_{a}\\langle \\Psi |H|\\Psi \\rangle=\\sum_{\\sigma,\\sigma'} (\\partial_{a}\\psi_{\\sigma'})H_{\\sigma'\\sigma}\\psi_{\\sigma} + \\psi_{\\sigma'}H_{\\sigma'\\sigma}(\\partial_{a}\\psi_{\\sigma})=2\\sum_{\\sigma,\\sigma'} (\\partial_{a}\\psi_{\\sigma'})H_{\\sigma'\\sigma}\\psi_{\\sigma}=\n",
    "2\\sum_{\\sigma,\\sigma'}|\\psi_{\\sigma'}|^2 \\frac{(\\partial_{a}\\psi_{\\sigma'})}{\\psi_{\\sigma'}}H_{\\sigma'\\sigma}\\frac{\\psi_{\\sigma}}{\\psi_{\\sigma'}}=$\n",
    "\n",
    "$\\sum_{\\sigma'}|\\psi_{\\sigma'}|^2 \\frac{\\partial_{a}\\psi_{\\sigma'}}{\\psi_{\\sigma'}}2\\sum_{\\sigma}H_{\\sigma'\\sigma}\\frac{\\psi_{\\sigma}}{\\psi_{\\sigma'}}$\n",
    "\n",
    "The cell below implements the above stuff (not very efficiently)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XXZMatrixElemets(Jz,Jp,Bz,sigmap):\n",
    "    \"\"\"\n",
    "    computes the matrix element of the periodic XXZ Hamiltonian for a given state sigmap\n",
    "    -----------------------------------------------------------------------------------\n",
    "    Parameters:\n",
    "    Jz, Jp, Bz: np.ndarray of shape (N), (N) and (N), respectively, and dtype=float:\n",
    "                XXZ parameters\n",
    "    sigmap:     np.ndarrray of dtype=int and shape (N)\n",
    "                spin-state, integer encoded (using 0 for down spin and 1 for up spin)\n",
    "    -----------------------------------------------------------------------------------            \n",
    "    Returns: 2-tuple of type (np.ndarray,np.ndarray)\n",
    "             sigmas:         np.ndarray of dtype=int and shape (?,N)\n",
    "                             the states for which there exist non-zero matrix elements for given sigmap\n",
    "             matrixelements: np.ndarray of dtype=float and shape (?)\n",
    "                             the non-zero matrix elements\n",
    "    \"\"\"\n",
    "    sigmas=[]\n",
    "    matrixelements=[]\n",
    "    N=len(Bz)\n",
    "    #the diagonal part is simply the sum of all Sz-Sz interactions plus a B field\n",
    "    diag=np.dot(sigmap-0.5,Bz)\n",
    "    \n",
    "    for site in range(N):\n",
    "        if sigmap[site]!=sigmap[(site+1)%N]:\n",
    "            diag-=0.25*Jz[site]\n",
    "        else:\n",
    "            diag+=0.25*Jz[site]\n",
    "    matrixelements.append(diag)\n",
    "    sigmas.append(np.copy(sigmap))\n",
    "    \n",
    "    #off-diagonal part:\n",
    "    for site in range(N):\n",
    "        if sigmap[site]!=sigmap[(site+1)%N]:\n",
    "            sig=np.copy(sigmap)\n",
    "            sig[site]=sig[(site+1)%N]\n",
    "            sig[(site+1)%N]=sigmap[site]\n",
    "            sigmas.append(sig)\n",
    "            matrixelements.append(Jp[site]/2)\n",
    "    return np.array(sigmas),np.array(matrixelements)\n",
    "\n",
    "def XXZLocalEnergy(Jz,Jp,Bz,sigmap,RNN):\n",
    "    \"\"\"\n",
    "    DEPRECATED\n",
    "    computes the local energy for the XXZ model:\n",
    "    ---------------------------------------------------------------------------------\n",
    "    Parameters:\n",
    "    Jz, Jp, Bz: np.ndarray of shape (N-1), (N-1) and (N), respectively, and dtype=float:\n",
    "                XXZ parameters\n",
    "    sigmap:     np.ndarrray of dtype=int and shape (N)\n",
    "                spin-state, integer encoded (using 0 for down spin and 1 for up spin)\n",
    "    RNN:        fully initialized RNNwavefunction object\n",
    "    ----------------------------------------------------------------------------------\n",
    "    Returns:\n",
    "    the local energy (float) for sigmapp\n",
    "    \"\"\"\n",
    "    sigmas,H=XXZMatrixElemets(Jz,Jp,Bz,sigmap)#note that sigmas[0,:]==sigmap\n",
    "    with RNN.graph.as_default():\n",
    "        inputs=tf.placeholder(dtype=tf.int32,shape=[len(sigmas),len(Bz)])\n",
    "        probs=RNN.probability(inputs,inputdim=2)\n",
    "        probabilities=sess.run(probs,feed_dict={inputs:sigmas})\n",
    "    \n",
    "    return H.dot(probabilities)/probabilities[0]\n",
    "\n",
    "def XXZLocalEnergies(Jz,Jp,Bz,sigmasp,RNN):\n",
    "    \"\"\"\n",
    "    computes the local energies for the periodic XXZ model for a given spin-state sample sigmasp:\n",
    "    Eloc(\\sigma')=\\sum_{sigma} H_{\\sigma'\\sigma}\\psi_{\\sigma}/\\psi_{\\sigma'}\n",
    "    ----------------------------------------------------------------------------\n",
    "    Parameters:\n",
    "    Jz, Jp, Bz: np.ndarray of shape (N), (N) and (N), respectively, and dtype=float:\n",
    "                XXZ parameters\n",
    "    sigmasp:    np.ndarrray of dtype=int and shape (numsamples,N)\n",
    "                spin-states, integer encoded (using 0 for down spin and 1 for up spin)\n",
    "    RNN:        fully initialized RNNwavefunction object\n",
    "    ----------------------------------------------------------------------------\n",
    "    Returns:\n",
    "    np.ndarray of shape (numsamples)and dtype=float containing the local energies for each samples\n",
    "    \"\"\"\n",
    "    sigmas=np.empty((0,len(Bz)))\n",
    "    H=np.empty(0)\n",
    "    slices=[]\n",
    "    for n in range(sigmasp.shape[0]):\n",
    "        sigmap=sigmasp[n,:]\n",
    "        temp1,temp2=XXZMatrixElemets(Jz,Jp,Bz,sigmap)#note that sigmas[0,:]==sigmap\n",
    "        H=np.append(H,temp2)\n",
    "        slices.append(slice(sigmas.shape[0],sigmas.shape[0]+temp1.shape[0]))\n",
    "        sigmas=np.append(sigmas,temp1,axis=0)\n",
    "    with RNN.graph.as_default():\n",
    "        temp_inputs=tf.placeholder(dtype=tf.int32,shape=[len(sigmas),len(Bz)])\n",
    "        temp_probs=RNN.probability(temp_inputs,inputdim=2,keepprob=keepprob)\n",
    "        log_probabilities=sess.run(temp_probs,feed_dict={temp_inputs:sigmas,keepprob:1.0})\n",
    "    localEnergies=[]\n",
    "    for n in range(len(slices)):\n",
    "        s=slices[n]\n",
    "        localEnergies.append(H[s].dot(np.exp(0.5*(log_probabilities[s]-log_probabilities[s][0]))))\n",
    "    return np.array(localEnergies)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A small check to confirm that the matrix elements are correct ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the follwing numbers should all be > 0\n",
      "[0.00746966 0.03474209 0.05454486 0.03474209 0.00746966 0.05454486\n",
      " 0.16440628 0.13713385 0.03474209 0.09005865 0.16440628 0.05454486\n",
      " 0.05454486 0.03474209 0.00746966 0.03474209 0.13713385 0.16440628\n",
      " 0.05454486 0.16440628 0.39829674 0.16440628 0.16440628 0.13713385\n",
      " 0.03474209 0.05454486 0.16440628 0.09005865 0.13713385 0.16440628\n",
      " 0.05454486 0.03474209 0.05454486 0.03474209 0.00746966 0.00746966\n",
      " 0.03474209 0.05454486 0.03474209 0.05454486 0.16440628 0.13713385\n",
      " 0.09005865 0.16440628 0.05454486 0.03474209 0.13713385 0.16440628\n",
      " 0.16440628 0.39829674 0.16440628 0.05454486 0.16440628 0.13713385\n",
      " 0.03474209 0.00746966 0.03474209 0.05454486 0.05454486 0.16440628\n",
      " 0.09005865 0.03474209 0.13713385 0.16440628 0.05454486 0.00746966\n",
      " 0.03474209 0.05454486 0.03474209 0.00746966]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import XXZED\n",
    "\n",
    "N_=8\n",
    "basis_=XXZED.binarybasisU1(N_,np.int(N_/2))\n",
    "\n",
    "basis=np.array([np.array(list(bin(b)[2::].zfill(N_))).astype(int) for b in basis_])\n",
    "\n",
    "Jz=np.ones(N_)\n",
    "Jp=-np.ones(N_)\n",
    "Bz=np.zeros(N_)\n",
    "\n",
    "H=np.zeros((basis.shape[0],basis.shape[0]))\n",
    "for n in range(basis.shape[0]):\n",
    "    sigmas,elements=XXZMatrixElemets(Jz,Jp,Bz,np.reshape(basis[n,:],(N_)))\n",
    "#     print(basis[n,:])\n",
    "#     print(sigmas)\n",
    "#     input()\n",
    "    for m in range(sigmas.shape[0]):\n",
    "        for b in range(basis.shape[0]):\n",
    "            if np.all(basis[b,:]==sigmas[m,:]):\n",
    "                H[b,n]=elements[m]\n",
    "eta,U=np.linalg.eigh(H)\n",
    "#print(np.nonzero(eta==np.min(eta))[0][0])\n",
    "print('the follwing numbers should all be > 0')\n",
    "print(U[:,np.nonzero(eta==np.min(eta))[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the following number should be ~ -3.65109341:  -3.6510934089371783\n"
     ]
    }
   ],
   "source": [
    "#print(np.sum(basis,axis=1))\n",
    "print ('the following number should be ~ -3.65109341: ',np.min(eta))\n",
    "#confirmed to be correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a checkpointed wave-function ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/maga/Dropbox/Work/RNN_wavefunctions\n",
      "INFO:tensorflow:Restoring parameters from /home/maga/Dropbox/Work/RNN_wavefunctions/RNNwavefunction_N8_units[500].ckpt\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /home/maga/Dropbox/Work/RNN_wavefunctions/RNNwavefunction_N8_units[500].ckpt\n\t [[Node: save_1/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2/tensor_names, save_1/RestoreV2/shape_and_slices)]]\n\nCaused by op 'save_1/RestoreV2', defined at:\n  File \"/home/maga/software/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/maga/software/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/maga/software/anaconda3/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/maga/software/anaconda3/lib/python3.6/asyncio/base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"/home/maga/software/anaconda3/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-11-6e6e2fe0abbb>\", line 6, in <module>\n    saver=tf.train.Saver()\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1338, in __init__\n    self.build()\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1347, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1384, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 835, in _build_internal\n    restore_sequentially, reshape)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 472, in _AddRestoreOps\n    restore_sequentially)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 886, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1463, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nNotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /home/maga/Dropbox/Work/RNN_wavefunctions/RNNwavefunction_N8_units[500].ckpt\n\t [[Node: save_1/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2/tensor_names, save_1/RestoreV2/shape_and_slices)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /home/maga/Dropbox/Work/RNN_wavefunctions/RNNwavefunction_N8_units[500].ckpt\n\t [[Node: save_1/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2/tensor_names, save_1/RestoreV2/shape_and_slices)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-6e6e2fe0abbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mwf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0msaver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/RNNwavefunction_N{0}_units{1}.ckpt'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1800\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1801\u001b[0m       sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1802\u001b[0;31m                {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1804\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /home/maga/Dropbox/Work/RNN_wavefunctions/RNNwavefunction_N8_units[500].ckpt\n\t [[Node: save_1/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2/tensor_names, save_1/RestoreV2/shape_and_slices)]]\n\nCaused by op 'save_1/RestoreV2', defined at:\n  File \"/home/maga/software/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/maga/software/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/maga/software/anaconda3/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/maga/software/anaconda3/lib/python3.6/asyncio/base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"/home/maga/software/anaconda3/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-11-6e6e2fe0abbb>\", line 6, in <module>\n    saver=tf.train.Saver()\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1338, in __init__\n    self.build()\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1347, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1384, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 835, in _build_internal\n    restore_sequentially, reshape)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 472, in _AddRestoreOps\n    restore_sequentially)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 886, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1463, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/home/maga/software/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nNotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /home/maga/Dropbox/Work/RNN_wavefunctions/RNNwavefunction_N8_units[500].ckpt\n\t [[Node: save_1/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2/tensor_names, save_1/RestoreV2/shape_and_slices)]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path=os.getcwd()\n",
    "print((path))\n",
    "with tf.variable_scope(wf.scope,reuse=tf.AUTO_REUSE):\n",
    "    with wf.graph.as_default():\n",
    "        saver=tf.train.Saver()\n",
    "        saver.restore(sess,path+'/RNNwavefunction_N{0}_units{1}.ckpt'.format(N,units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanEnergy=[]\n",
    "varEnergy=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean(E): -1.9863784604728223 \\pm 1.4491462665157018\n",
      "mean(E): -2.004730501356721 \\pm 1.4334951565727612\n",
      "mean(E): -2.003879830124974 \\pm 1.4449950229400343\n",
      "mean(E): -2.0025246302694084 \\pm 1.4343775697986925\n",
      "mean(E): -1.9839182492166758 \\pm 1.4239380651922435\n",
      "mean(E): -1.9967129244819284 \\pm 1.414758551645511\n",
      "mean(E): -2.0282533726483583 \\pm 1.412893688232432\n",
      "mean(E): -2.0195562712401154 \\pm 1.4142660043841133\n",
      "mean(E): -2.0228245173320176 \\pm 1.428550507077093\n",
      "mean(E): -2.003485303504765 \\pm 1.4097282911273208\n",
      "mean(E): -2.026028910920024 \\pm 1.413109418040019\n",
      "mean(E): -2.040016864052415 \\pm 1.4112268825573804\n",
      "mean(E): -2.022483886407316 \\pm 1.4145885145371155\n",
      "mean(E): -2.0562956987947225 \\pm 1.4149746120959381\n",
      "mean(E): -2.0506620590150355 \\pm 1.3950235268002105\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-3766b28a43cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumsamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumsamples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minputdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeepprob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mkeepprob\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mlocal_energies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mXXZLocalEnergies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mJp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mmeanE\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_energies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mvarE\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_energies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-152b5ddbd905>\u001b[0m in \u001b[0;36mXXZLocalEnergies\u001b[0;34m(Jz, Jp, Bz, sigmasp, RNN)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0msigmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msigmasp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mtemp1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtemp2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mXXZMatrixElemets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mJp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msigmap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#note that sigmas[0,:]==sigmap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mH\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtemp2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mslices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigmas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msigmas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtemp1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0msigmas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigmas\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtemp1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(arr, values, axis)\u001b[0m\n\u001b[1;32m   4526\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4527\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4528\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path=os.getcwd()\n",
    "Jz=np.ones(N)\n",
    "Jp=-np.ones(N)\n",
    "Bz=np.zeros(N)\n",
    "\n",
    "#for a given network, generate a large number of samples:\n",
    "numsamples=20000\n",
    "lr=np.float32(0.01)\n",
    "# with tf.variable_scope(wf.scope,reuse=tf.AUTO_REUSE):\n",
    "#     with wf.graph.as_default():\n",
    "#         optimizer=tf.train.AdamOptimizer(learning_rate=learningrate)\n",
    "#         #sess.run(tf.variables_initializer(optimizer.variables()),feed_dict={learningrate: lr})\n",
    "with tf.variable_scope(wf.scope,reuse=tf.AUTO_REUSE):\n",
    "    with wf.graph.as_default():\n",
    "        saver=tf.train.Saver()\n",
    "        Eloc=tf.placeholder(dtype=tf.float32,shape=[numsamples])\n",
    "        samp=tf.placeholder(dtype=tf.int32,shape=[numsamples,N])\n",
    "        log_probs_=wf.probability(samp,inputdim=2,keepprob=keepprob)\n",
    "        #now calculate the fake cost function:\n",
    "        cost=tf.reduce_mean(tf.multiply(log_probs_,Eloc)) #factor of 2 in the above equation \n",
    "                                          #cancels when taking log(sqrt(prob))=log(sqrt(psi^2))`\n",
    "                                          #=log(psi)=2*log(psi^2)->log(psi)=1/2*log(psi^2)=1/2*log_probs\n",
    "        gradients, variables = zip(*optimizer.compute_gradients(cost))\n",
    "        #clipped_gradients,_=tf.clip_by_global_norm(gradients,1.0)\n",
    "        optstep=optimizer.apply_gradients(zip(gradients,variables))\n",
    "        sess.run(tf.variables_initializer(optimizer.variables()),feed_dict={learningrate: lr})\n",
    "for it in range(1000):\n",
    "    samples,log_probs=sess.run(wf.sample(numsamples=numsamples,inputdim=2,keepprob=keepprob),feed_dict={keepprob:1})\n",
    "    local_energies=XXZLocalEnergies(Jz,Jp,Bz,samples,wf)\n",
    "    meanE=np.mean(local_energies)\n",
    "    varE=np.var(local_energies)\n",
    "    meanEnergy.append(meanE)   \n",
    "    varEnergy.append(varE)\n",
    "    print('mean(E): {0} \\pm {1}'.format(meanE,np.sqrt(varE)))\n",
    "    with tf.variable_scope(wf.scope,reuse=tf.AUTO_REUSE):\n",
    "        with wf.graph.as_default():\n",
    "\n",
    "            sess.run(optstep,feed_dict={Eloc:local_energies,samp:samples,learningrate: lr,keepprob:1.0})\n",
    "            if it%10==0:\n",
    "                saver.save(sess,path+'/RNNwavefunction_N{0}_units{1}.ckpt'.format(N,units))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    }
   ],
   "source": [
    "a=[1,2,3]\n",
    "bl=''\n",
    "for n in a:\n",
    "    bl+=str(n)\n",
    "print(bl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
